{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('start')\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from os import mkdir,path\n",
    "from shutil import rmtree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_index=1\n",
    "image_index='b'\n",
    "big_height=70\n",
    "small_height=27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path.isdir('test'):\n",
    "    rmtree('test')\n",
    "if path.isdir('results'):\n",
    "    rmtree('results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir('test')\n",
    "mkdir('results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_image=Image.open('data/{}_small.png'.format(image_index)).convert('RGB')\n",
    "# small_image.save('test/small.png')\n",
    "\n",
    "# big_image=Image.open('data/{}_big.png'.format(image_index)).convert('RGB')\n",
    "# big_image_cv2_plis=cv2.imread('data/{}_big.png'.format(image_index))\n",
    "\n",
    "# small_w,small_h=small_image.size\n",
    "\n",
    "small_image=Image.open('data/dron/{}-{}.JPG'.format(image_index,small_height)).convert('RGB')\n",
    "# small_image=small_image.resize((int(1920 * small_height/big_height),int(1080* small_height/big_height)))\n",
    "small_image=small_image.resize((1920,1080))\n",
    "small_image=small_image.crop((420,0,1500,1080))\n",
    "\n",
    "small_image.save('test/small.png')\n",
    "small_image.save('results/a.png')\n",
    "\n",
    "big_image=Image.open('data/dron/{}-{}.JPG'.format(image_index,big_height)).convert('RGB')\n",
    "big_image=big_image.resize((1920,1080))\n",
    "big_image=big_image.crop((420,0,1500,1080))\n",
    "\n",
    "big_image.save('results/b.png')\n",
    "\n",
    "\n",
    "y=0\n",
    "x=420\n",
    "h=1080\n",
    "w=1920\n",
    "big_image_cv2_plis=cv2.imread('data/dron/{}-{}.JPG'.format(image_index,big_height))\n",
    "cv2.resize(big_image_cv2_plis,(1920,1080))\n",
    "big_image_cv2_plis = big_image_cv2_plis[y:y+h, x:x+w]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(big_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(small_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare einvironemnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms_small = transforms.Compose([\n",
    "#     transforms.CenterCrop(64),\n",
    "    # below are for tests\n",
    "#     transforms.ColorJitter(brightness=1,contrast=1,saturation=1),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "data_transforms_big = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_image_transform=data_transforms_big(big_image)\n",
    "plt.imsave('test/big.png',big_image_transform.numpy()[2])\n",
    "\n",
    "big_image_transform=big_image_transform.numpy().transpose(1, 2, 0)\n",
    "big_image_transform=big_image_transform.astype(np.float32)\n",
    "plt.imsave('test/big2.png',big_image_transform[0])\n",
    "# big_image_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_images_torch=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rotate_angle in range(0,360,10):\n",
    "    rotation_45_procent = (rotate_angle%45)/45\n",
    "    scale=(rotation_45_procent * 0.41)+1\n",
    "    w,h=small_image.size\n",
    "    w_scale=int(w*scale)\n",
    "    h_scale=int(h*scale)\n",
    "    \n",
    "    small_image_transform=small_image.resize((w_scale,h_scale),Image.ANTIALIAS).rotate(rotate_angle)\n",
    "    small_image_transform=small_image.rotate(rotate_angle)\n",
    "    small_image_transform.save('test/zzz{}.png'.format(rotate_angle))\n",
    "    \n",
    "    small_image_torch = data_transforms_small(small_image_transform)\n",
    "    \n",
    "    if rotate_angle%20==0:\n",
    "        plt.imsave('test/test-{}.png'.format(rotate_angle),small_image_torch.numpy()[0])\n",
    "        \n",
    "    \n",
    "    small_images_torch.append(small_image_torch.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(small_images_torch[10].size())\n",
    "len(small_images_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv2 template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_m=-100\n",
    "max_loc=None\n",
    "\n",
    "for torch_image in small_images_torch:\n",
    "    template_image=torch_image[0].numpy().transpose(1, 2, 0)\n",
    "    template_image=template_image.astype(np.float32)\n",
    "    \n",
    "    w, h = template_image.shape[:-1]\n",
    "    \n",
    "    result = cv2.matchTemplate(big_image_transform, template_image, cv2.TM_CCOEFF_NORMED)\n",
    "  \n",
    "    if np.amax(result)>max_m:\n",
    "        max_m=np.amax(result)\n",
    "        print(max_m,max_loc)\n",
    "    loc = np.where(result >= max_m)\n",
    "\n",
    "    for pt in zip(*loc[::-1]): \n",
    "        max_loc=pt\n",
    "        print(max_m,max_loc)\n",
    "        \n",
    "\n",
    "print(max_m,max_loc)\n",
    "cv2.rectangle(big_image_cv2_plis, max_loc, (max_loc[0]+ h, max_loc[1]+ w),(0, 0, 255), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('results/finall_image.png', big_image_cv2_plis)\n",
    "plt.imshow(big_image_cv2_plis[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
