{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('start')\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "import cv2\n",
    "from shutil import rmtree\n",
    "from os import mkdir,path\n",
    "\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path.isdir('test'):\n",
    "    rmtree('test')\n",
    "if path.isdir('results'):\n",
    "    rmtree('results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir('test')\n",
    "mkdir('test/small')\n",
    "mkdir('test/crop')\n",
    "mkdir('results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color=(0,0,255)\n",
    "thickness=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_picture = Image.open('data/1-small.png').convert('RGB')\n",
    "big_picture = Image.open('data/1-big.png').convert('RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(pretrained=True).to(device)\n",
    "\n",
    "# co robi to ni≈ºej?\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-2])).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# for i in range(0,256-64,5):\n",
    "        \n",
    "#     for j in range(0,256-64,5):\n",
    "        \n",
    "#         left=i\n",
    "#         right = i+ 64\n",
    "        \n",
    "#         top=j\n",
    "#         bottom = j+64\n",
    "        \n",
    "#         start_point=(left,top)\n",
    "#         end_point=(right,bottom)\n",
    "        \n",
    "#         crop=big.crop((left,top,right,bottom))\n",
    "\n",
    "# #         hash0=imagehash.average_hash(small)\n",
    "#         hash1=imagehash.average_hash(crop)\n",
    "#         for r in range(0,360,5):\n",
    "            \n",
    "#             small_test=small.rotate(r)\n",
    "#             small_test=small_test.resize((64,64))\n",
    "# #             small_test=small\n",
    "\n",
    "#             hash0=imagehash.average_hash(small_test)\n",
    "            \n",
    "           \n",
    "#             if hash0 - hash1 <12:\n",
    "#                 cv_big = np.array(big_color.convert('RGB'))\n",
    "#                 cv_big=cv_big[:,:,::-1].copy()\n",
    "\n",
    "#                 result=cv2.rectangle(cv_big,start_point,end_point,color,thickness)\n",
    "#                 result = cv2.cvtColor(result,cv2.COLOR_BGR2RGB)\n",
    "#                 big_color=Image.fromarray(result)\n",
    "\n",
    "#                 small_test.save('test/small/{}-{}-{}.png'.format(i,j,r))\n",
    "#                 crop.save('test/crop/{}-{}-{}.png'.format(i,j,r))\n",
    "                \n",
    "#                 print(start_point,end_point)\n",
    "#                 break\n",
    "            \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "#     transforms.CenterCrop(10),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## working with photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_picture_torch = data_transforms(big_picture).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_picture_torch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_picture_torch.unsqueeze(0).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_out_big=model(big_picture_torch.unsqueeze(0)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_out_big.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small imgs to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_picture.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_picture.rotate(30).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_pictures_rotated_torch = []\n",
    "for rotate_angle in range(0,360,10):\n",
    "    small_picture_rotated = small_picture.rotate(rotate_angle)\n",
    "    small_pictures_rotated_torch.append(data_transforms(small_picture_rotated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_pictures_rotated_torch[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ,,Total number of training examples present in a single batch\"\n",
    "small_pictures_batch = torch.stack(small_pictures_rotated_torch).to(device)\n",
    "\n",
    "# Czemu to devie?>\n",
    "# small_pictures_batch = torch.stack(small_pictures_rotated_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_pictures_batch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_outs_small = model(small_pictures_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_outs_small.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_big, w_big = resnet_out_big.size()[1:]\n",
    "h_big, w_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_out_big.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for small_picture_resnet in resnet_outs_small:\n",
    "    h_small, w_small = small_picture_resnet.size()[1:]\n",
    "    print(h_small,w_small)\n",
    "    \n",
    "    for h_shift in range(h_big-h_small):\n",
    "        for w_shift in range(w_big-w_small):\n",
    "            resnet_out_big_cut=resnet_out_big[:, h_shift:h_shift+h_small, w_shift:w_shift+w_small]\n",
    "            similarity_measure = torch.mean((resnet_out_big_cut - small_picture_resnet) ** 2).item()\n",
    "#             if similarity_measure>1:\n",
    "            print(similarity_measure)\n",
    "                \n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
